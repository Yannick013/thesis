{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating training, validation and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\yanni\\OneDrive\\Bureaublad\\RadboudJaar3\\Thesis\\project files\\thesisenv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes in the dataset: ['NORMAL', 'PNEUMONIA']\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import torchvision.models as models\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import os\n",
    "import kagglehub\n",
    "import zipfile \n",
    "with zipfile.ZipFile('chest-xray-pneumonia.zip', 'r') as zip_ref:\n",
    "    zip_ref.extractall('chest_xray')\n",
    "\n",
    "device = torch.device(\"cuda:0\")                               #We use the GPU for training \n",
    "\n",
    "transform = transforms.Compose([                              #transform function \n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.Grayscale(num_output_channels=1),              #Since the images are grayscale\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "''' \n",
    "Now we define the training, validation and test sets\n",
    "'''\n",
    "training_dir = './chest_xray/chest_xray/train' \n",
    "training_set = datasets.ImageFolder(root=training_dir, transform=transform)\n",
    "\n",
    "validation_dir = './chest_xray/chest_xray/val'\n",
    "validation_set = datasets.ImageFolder(root=validation_dir, transform=transform)\n",
    "\n",
    "test_dir = './chest_xray/chest_xray/test'\n",
    "test_set = datasets.ImageFolder(root=test_dir, transform=transform)\n",
    "\n",
    "'''\n",
    "Now we define the training loaders and validation loaders\n",
    "'''\n",
    "\n",
    "training_loader = torch.utils.data.DataLoader(training_set, batch_size=32, shuffle=True, num_workers=4, pin_memory=True, persistent_workers=True)\n",
    "validation_loader = torch.utils.data.DataLoader(validation_set, batch_size=32, shuffle=False)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=32, shuffle=False)\n",
    "\n",
    "classes = training_set.classes\n",
    "print(\"Classes in the dataset:\", classes)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'training_loader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 17\u001b[39m\n\u001b[32m     14\u001b[39m         plt.imshow(np.transpose(npimg, (\u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m, \u001b[32m0\u001b[39m)))\n\u001b[32m     16\u001b[39m \u001b[38;5;66;03m# Get a batch of images and labels\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m dataiter = \u001b[38;5;28miter\u001b[39m(\u001b[43mtraining_loader\u001b[49m)\n\u001b[32m     18\u001b[39m images, labels = \u001b[38;5;28mnext\u001b[39m(dataiter)\n\u001b[32m     20\u001b[39m \u001b[38;5;66;03m# Create a grid from the images and show them\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'training_loader' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torchvision\n",
    "\n",
    "# Helper function for inline image display\n",
    "def matplotlib_imshow(img, one_channel=False):\n",
    "    if one_channel:\n",
    "        img = img.mean(dim=0)\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    if one_channel:\n",
    "        plt.imshow(npimg, cmap=\"Greys\")\n",
    "    else:\n",
    "        plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "\n",
    "# Get a batch of images and labels\n",
    "dataiter = iter(training_loader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# Create a grid from the images and show them\n",
    "img_grid = torchvision.utils.make_grid(images)\n",
    "matplotlib_imshow(img_grid, one_channel=True)\n",
    "\n",
    "# Use the correct classes from the ImageFolder dataset\n",
    "print('  '.join([training_set.classes[label.item()] for label in labels]))  # Accessing the class name properly\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resnet-152 construction & initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################\n",
    "### SETTINGS\n",
    "##########################\n",
    "\n",
    "# Hyperparameters\n",
    "RANDOM_SEED = 1\n",
    "LEARNING_RATE = 0.001\n",
    "NUM_EPOCHS = 40\n",
    "\n",
    "# Architecture\n",
    "NUM_FEATURES = 224,224\n",
    "NUM_CLASSES = 2\n",
    "BATCH_SIZE = 32\n",
    "DEVICE = 'cuda:0' # default GPU device\n",
    "GRAYSCALE = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################\n",
    "### MODEL copied from https://github.com/rasbt/deeplearning-models/blob/master/pytorch_ipynb/cnn/cnn-resnet152-celeba.ipynb\n",
    "##########################\n",
    "\n",
    "import os\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "def conv3x3(in_planes, out_planes, stride=1):\n",
    "    \"\"\"3x3 convolution with padding\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                     padding=1, bias=False)\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n",
    "                               padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(planes * 4)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "\n",
    "    def __init__(self, block, layers, num_classes, grayscale):\n",
    "        self.inplanes = 64\n",
    "        if grayscale:\n",
    "            in_dim = 1\n",
    "        else:\n",
    "            in_dim = 3\n",
    "        super(ResNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_dim, 64, kernel_size=7, stride=2, padding=3,\n",
    "                               bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
    "        #self.avgpool = nn.AvgPool2d(7, stride=1, padding=2)                origineel\n",
    "        self.avgpool = nn.AdaptiveMaxPool2d((1,1))                          #deepseek suggestie \n",
    "        #self.fc = nn.Linear(2048 * block.expansion, num_classes)           origneel \n",
    "        self.fc = nn.Linear(2048, num_classes)                              #deepseek suggestie\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, (2. / n)**.5)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        #x = torch.flatten(x,1) #weghalen\n",
    "\n",
    "        x = x.view(x.size(0), -1)\n",
    "        logits = self.fc(x)\n",
    "        probas = F.softmax(logits, dim=1)\n",
    "        return logits, probas\n",
    "\n",
    "\n",
    "\n",
    "def resnet152(num_classes, grayscale):\n",
    "    \"\"\"Constructs a ResNet-152 model.\"\"\"\n",
    "    model = ResNet(block=Bottleneck, \n",
    "                   layers=[3, 4, 36, 3],\n",
    "                   num_classes=num_classes,\n",
    "                   grayscale=grayscale)\n",
    "    return model\n",
    "\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "\n",
    "##########################\n",
    "### COST AND OPTIMIZER\n",
    "##########################\n",
    "\n",
    "model = resnet152(NUM_CLASSES, GRAYSCALE)\n",
    "model.to(DEVICE)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1, 224, 224])\n",
      "Epoch: 001/040 | Batch 0000/0163 | Cost: 1.9249\n",
      "torch.Size([32, 1, 224, 224])\n",
      "torch.Size([32, 1, 224, 224])\n",
      "torch.Size([32, 1, 224, 224])\n",
      "torch.Size([32, 1, 224, 224])\n",
      "torch.Size([32, 1, 224, 224])\n",
      "torch.Size([32, 1, 224, 224])\n",
      "torch.Size([32, 1, 224, 224])\n",
      "torch.Size([32, 1, 224, 224])\n",
      "torch.Size([32, 1, 224, 224])\n",
      "torch.Size([32, 1, 224, 224])\n",
      "torch.Size([32, 1, 224, 224])\n",
      "torch.Size([32, 1, 224, 224])\n",
      "torch.Size([32, 1, 224, 224])\n",
      "torch.Size([32, 1, 224, 224])\n",
      "torch.Size([32, 1, 224, 224])\n",
      "torch.Size([32, 1, 224, 224])\n",
      "torch.Size([32, 1, 224, 224])\n",
      "torch.Size([32, 1, 224, 224])\n",
      "torch.Size([32, 1, 224, 224])\n",
      "torch.Size([32, 1, 224, 224])\n",
      "torch.Size([32, 1, 224, 224])\n",
      "torch.Size([32, 1, 224, 224])\n",
      "torch.Size([32, 1, 224, 224])\n",
      "torch.Size([32, 1, 224, 224])\n",
      "torch.Size([32, 1, 224, 224])\n",
      "torch.Size([32, 1, 224, 224])\n",
      "torch.Size([32, 1, 224, 224])\n",
      "torch.Size([32, 1, 224, 224])\n",
      "torch.Size([32, 1, 224, 224])\n",
      "torch.Size([32, 1, 224, 224])\n",
      "torch.Size([32, 1, 224, 224])\n",
      "torch.Size([32, 1, 224, 224])\n",
      "torch.Size([32, 1, 224, 224])\n",
      "torch.Size([32, 1, 224, 224])\n",
      "torch.Size([32, 1, 224, 224])\n",
      "torch.Size([32, 1, 224, 224])\n",
      "torch.Size([32, 1, 224, 224])\n",
      "torch.Size([32, 1, 224, 224])\n",
      "torch.Size([32, 1, 224, 224])\n",
      "torch.Size([32, 1, 224, 224])\n",
      "torch.Size([32, 1, 224, 224])\n",
      "torch.Size([32, 1, 224, 224])\n",
      "torch.Size([32, 1, 224, 224])\n",
      "torch.Size([32, 1, 224, 224])\n",
      "torch.Size([32, 1, 224, 224])\n",
      "torch.Size([32, 1, 224, 224])\n",
      "torch.Size([32, 1, 224, 224])\n",
      "torch.Size([32, 1, 224, 224])\n",
      "torch.Size([32, 1, 224, 224])\n",
      "torch.Size([32, 1, 224, 224])\n",
      "Epoch: 001/040 | Batch 0050/0163 | Cost: 0.0887\n",
      "torch.Size([32, 1, 224, 224])\n",
      "torch.Size([32, 1, 224, 224])\n",
      "torch.Size([32, 1, 224, 224])\n",
      "torch.Size([32, 1, 224, 224])\n",
      "torch.Size([32, 1, 224, 224])\n",
      "torch.Size([32, 1, 224, 224])\n",
      "torch.Size([32, 1, 224, 224])\n",
      "torch.Size([32, 1, 224, 224])\n",
      "torch.Size([32, 1, 224, 224])\n",
      "torch.Size([32, 1, 224, 224])\n",
      "torch.Size([32, 1, 224, 224])\n",
      "torch.Size([32, 1, 224, 224])\n",
      "torch.Size([32, 1, 224, 224])\n",
      "torch.Size([32, 1, 224, 224])\n",
      "torch.Size([32, 1, 224, 224])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 21\u001b[39m\n\u001b[32m     18\u001b[39m model.train()\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, (features, targets) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(training_loader):\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m     features = \u001b[43mfeatures\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDEVICE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     22\u001b[39m     targets = targets.to(DEVICE)\n\u001b[32m     24\u001b[39m     \u001b[38;5;28mprint\u001b[39m(features.shape)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "def compute_accuracy(model, data_loader, device):\n",
    "    correct_pred, num_examples = 0, 0\n",
    "    for i, (features, targets) in enumerate(data_loader):\n",
    "            \n",
    "        features = features.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        logits, probas = model(features)\n",
    "        _, predicted_labels = torch.max(probas, 1)\n",
    "        num_examples += targets.size(0)\n",
    "        correct_pred += (predicted_labels == targets).sum()\n",
    "    return correct_pred.float()/num_examples * 100\n",
    "    \n",
    "\n",
    "start_time = time.time()\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    \n",
    "    model.train()\n",
    "    for batch_idx, (features, targets) in enumerate(training_loader):\n",
    "        \n",
    "        features = features.to(DEVICE)\n",
    "        targets = targets.to(DEVICE)\n",
    "\n",
    "        print(features.shape)\n",
    "        \n",
    "        ### FORWARD AND BACK PROP\n",
    "        logits, probas = model(features)\n",
    "        cost = F.cross_entropy(logits, targets)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        cost.backward()\n",
    "        \n",
    "        ### UPDATE MODEL PARAMETERS\n",
    "        optimizer.step()\n",
    "        \n",
    "        ### LOGGING\n",
    "        if not batch_idx % 50:\n",
    "            print ('Epoch: %03d/%03d | Batch %04d/%04d | Cost: %.4f' \n",
    "                   %(epoch+1, NUM_EPOCHS, batch_idx, \n",
    "                     len(training_loader), cost))\n",
    "\n",
    "        \n",
    "\n",
    "    model.eval()\n",
    "    with torch.set_grad_enabled(False): # save memory during inference\n",
    "        print('Epoch: %03d/%03d | Train: %.3f%% | Valid: %.3f%%' % (\n",
    "              epoch+1, NUM_EPOCHS, \n",
    "              compute_accuracy(model, training_loader, device=DEVICE),\n",
    "              compute_accuracy(model, validation_loader, device=DEVICE)))\n",
    "        \n",
    "    print('Time elapsed: %.2f min' % ((time.time() - start_time)/60))\n",
    "    \n",
    "print('Total Training Time: %.2f min' % ((time.time() - start_time)/60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.set_grad_enabled(False): # save memory during inference\n",
    "    print('Test accuracy: %.2f%%' % (compute_accuracy(model, test_loader, device=DEVICE)))\n",
    "\n",
    "\n",
    "for batch_idx, (features, targets) in enumerate(test_loader):\n",
    "\n",
    "    features = features\n",
    "    targets = targets\n",
    "    break\n",
    "    \n",
    "plt.imshow(np.transpose(features[0], (1, 2, 0)))\n",
    "\n",
    "model.eval()\n",
    "logits, probas = model(features.to(DEVICE)[0, None])\n",
    "print('Probability Female %.2f%%' % (probas[0][0]*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesisenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
